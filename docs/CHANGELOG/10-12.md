今天搞了个 NFA 来自动分词

主要是靠这个表
把所有 token 类型分成4种

- 单字符
- 块状
- 条状
- 行状（暂时好像没考虑行状。。。）
- 空格

```rust
pub fn lexed(&mut self) {
    let state_table = [
        (0, 0, 0, 0, 0),
        (2, 3, 0, 5, 6),
        (2, 3, 0, 5, 6),
        (3, 3, 4, 3, 3),
        (2, 3, 0, 5, 6),
        (2, 3, 0, 5, 6),
        (2, 3, 0, 5, 6),
    ];
    // ...
}
```

然后发现代码重复性很大，而且几乎都可以抽离成配置文件自动生成
基本的功能已经实现了
现在可以正常获取到一个 `(TokenKind, text)` 的元组表示单个 Token
下一步构建 AST 可以再放放， 因为还需要进一步补一下理论

明天要把 path 和 io 的一些基础方法简单封装一下
rust 的这两个标准库简直稀烂

rust 的正则也是稀烂

此外今天大致写了一下配置文件
打算就简单点，怎么好解析怎么写，长这样

```text
[[Operator]]
SEMI = ";"
[[END]]

[[Literal]]
ID = /^[a-zA-Z0-9]+$/
[[END]]

[[Keyword]]
IMPORT = "import"
[[END]]

[[Other]]
WHITE_SPACE = /\n|\t|\r/
[[END]]
```

上面是 token 定义的
接下来要补上文法定义
然后根据文法来生成 AST